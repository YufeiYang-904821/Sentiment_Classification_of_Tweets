{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22c6fcc6",
   "metadata": {},
   "source": [
    "# Assignment 3: Sentiment Classification of Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61ea855",
   "metadata": {},
   "source": [
    "### Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3479f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train data\n",
    "train_full = open(\"./data/train_full.csv\",'r').readlines()[1:]\n",
    "train_count = open(\"./data/train_count.csv\",'r').readlines()[1:]\n",
    "train_tfidf = open(\"./data/train_tfidf.csv\",'r').readlines()[1:]\n",
    "train_glove = open(\"./data/train_glove.csv\",'r').readlines()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27cf5ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read development data\n",
    "dev_full = open(\"./data/dev_full.csv\",'r').readlines()[1:]\n",
    "dev_count = open(\"./data/dev_count.csv\",'r').readlines()[1:]\n",
    "dev_tfidf = open(\"./data/dev_tfidf.csv\",'r').readlines()[1:]\n",
    "dev_glove = open(\"./data/dev_glove.csv\",'r').readlines()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6952d36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test data\n",
    "test_full = open(\"./data/test_full.csv\",'r').readlines()[1:]\n",
    "test_count = open(\"./data/test_count.csv\",'r').readlines()[1:]\n",
    "test_tfidf = open(\"./data/test_tfidf.csv\",'r').readlines()[1:]\n",
    "test_glove = open(\"./data/test_glove.csv\",'r').readlines()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "732f755f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features from data\n",
    "def get_feature(data):\n",
    "    feature = []\n",
    "    for line in data:\n",
    "         feature.append(eval(line.strip().split('\\\"')[1:-1][0]))\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1de5047",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count_fea = get_feature(train_count)\n",
    "train_tfidf_fea = get_feature(train_tfidf)\n",
    "train_glove_fea = get_feature(train_glove)\n",
    "\n",
    "dev_count_fea = get_feature(dev_count)\n",
    "dev_tfidf_fea = get_feature(dev_tfidf)\n",
    "dev_glove_fea = get_feature(dev_glove)\n",
    "\n",
    "test_count_fea = get_feature(test_count)\n",
    "test_tfidf_fea = get_feature(test_tfidf)\n",
    "test_glove_fea = get_feature(test_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc063b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make features in tfidf and count have same dimension\n",
    "vocab = open(\"./data/vocab.txt\",'r').readlines()\n",
    "\n",
    "def extend_dimension(feature):\n",
    "    extended_feature = []\n",
    "    for i in range(len(feature)):\n",
    "        counts = [0 for j in range(len(vocab))]\n",
    "        for instance in feature[i]:\n",
    "            counts[instance[0]] = instance[1]\n",
    "        extended_feature.append(counts)\n",
    "    return extended_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c43f6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_train_count_fea = extend_dimension(train_count_fea)\n",
    "extended_dev_count_fea = extend_dimension(dev_count_fea)\n",
    "extended_test_count_fea = extend_dimension(test_count_fea)\n",
    "\n",
    "extended_train_tfidf_fea = extend_dimension(train_tfidf_fea)\n",
    "extended_dev_tfidf_fea = extend_dimension(dev_tfidf_fea)\n",
    "extended_test_tfidf_fea = extend_dimension(test_tfidf_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49e4386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract labels from data\n",
    "def get_label(data):\n",
    "    label = []\n",
    "    for line in data:\n",
    "        label.append(line.strip().split(',')[0])\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17345284",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = get_label(train_count)\n",
    "dev_label = get_label(dev_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f11c232",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c1f7c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from random import random\n",
    "prior_neg = Counter(train_label)[\"neg\"] / len(train_label)\n",
    "dev_neg = Counter(dev_label)[\"neg\"] / len(dev_label)\n",
    "prior_neu = Counter(train_label)[\"neu\"] / len(train_label)\n",
    "dev_neu = Counter(dev_label)[\"neu\"] / len(dev_label)\n",
    "prior_pos = Counter(train_label)[\"pos\"] / len(train_label)\n",
    "dev_pos = Counter(dev_label)[\"pos\"] / len(dev_label)\n",
    "\n",
    "def weight_random(dev_label, prior_neg, prior_neu, prior_pos):\n",
    "    error = 0 \n",
    "    error_count = 0\n",
    "    random_prediction = []\n",
    "    for i in range(len(dev_label)):\n",
    "        if random() < prior_neg:\n",
    "            random_prediction.append(\"neg\")\n",
    "        elif prior_neg < random() < prior_neg + prior_neu:\n",
    "            random_prediction.append(\"neu\")\n",
    "        else:\n",
    "            random_prediction.append(\"pos\")\n",
    "    return random_prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89b6260e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "def evaluate(predict, label):\n",
    "    acc = accuracy_score(predict, label)\n",
    "    precision_recall_fscore = precision_recall_fscore_support(label, predict, average='macro')\n",
    "    return acc, precision_recall_fscore[0], precision_recall_fscore[1], precision_recall_fscore[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d087ca43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Random Baseline Score\n",
      "Accuracy:  0.38\n",
      "Precision:  0.34\n",
      "Recall:  0.34\n",
      "F1 Socre:  0.33\n"
     ]
    }
   ],
   "source": [
    "baseline_score = evaluate(weight_random(dev_label, prior_neg, prior_neu, prior_pos), dev_label)\n",
    "print(\"Weighted Random Baseline Score\")\n",
    "print(\"Accuracy: \", round(baseline_score[0],2))\n",
    "print(\"Precision: \", round(baseline_score[1],2))\n",
    "print(\"Recall: \", round(baseline_score[2],2))\n",
    "print(\"F1 Socre: \", round(baseline_score[3],2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774b0b47",
   "metadata": {},
   "source": [
    "### Training and Developing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab70730",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0f33c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cee09a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr_count = LogisticRegression().fit(extended_train_count_fea, train_label)\n",
    "lr_count_predict = lr_count.predict(extended_dev_count_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e43e4d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with count feature Score\n",
      "Accuracy:  0.74\n",
      "Precision:  0.75\n",
      "Recall:  0.76\n",
      "F1 Socre:  0.76\n"
     ]
    }
   ],
   "source": [
    "lr_count_score = evaluate(lr_count_predict, dev_label)\n",
    "print(\"Logistic Regression with count feature Score\")\n",
    "print(\"Accuracy: \", round(lr_count_score[0],2))\n",
    "print(\"Precision: \", round(lr_count_score[1],2))\n",
    "print(\"Recall: \", round(lr_count_score[2],2))\n",
    "print(\"F1 Socre: \", round(lr_count_score[3],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bc0f99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr_tfidf = LogisticRegression().fit(extended_train_tfidf_fea, train_label)\n",
    "lr_tfidf_predict = lr_tfidf.predict(extended_dev_tfidf_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6f07bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with tfidf feature Score\n",
      "Accuracy:  0.74\n",
      "Precision:  0.76\n",
      "Recall:  0.76\n",
      "F1 Socre:  0.76\n"
     ]
    }
   ],
   "source": [
    "lr_tfidf_score = evaluate(lr_tfidf_predict, dev_label)\n",
    "print(\"Logistic Regression with tfidf feature Score\")\n",
    "print(\"Accuracy: \", round(lr_tfidf_score[0],2))\n",
    "print(\"Precision: \", round(lr_tfidf_score[1],2))\n",
    "print(\"Recall: \", round(lr_tfidf_score[2],2))\n",
    "print(\"F1 Socre: \", round(lr_tfidf_score[3],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "295b4fbd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr_glove = LogisticRegression().fit(train_glove_fea, train_label)\n",
    "lr_glove_predict = lr_glove.predict(dev_glove_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18ed2d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with glove feature Score\n",
      "Accuracy:  0.68\n",
      "Precision:  0.69\n",
      "Recall:  0.7\n",
      "F1 Socre:  0.7\n"
     ]
    }
   ],
   "source": [
    "lr_glove_score = evaluate(lr_glove_predict, dev_label)\n",
    "print(\"Logistic Regression with glove feature Score\")\n",
    "print(\"Accuracy: \", round(lr_glove_score[0],2))\n",
    "print(\"Precision: \", round(lr_glove_score[1],2))\n",
    "print(\"Recall: \", round(lr_glove_score[2],2))\n",
    "print(\"F1 Socre: \", round(lr_glove_score[3],2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6081601",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4fc8d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c9f410ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_count = KNeighborsClassifier(n_neighbors=23)\n",
    "knn_count.fit(extended_train_count_fea, train_label)\n",
    "knn_count_predict = knn_count.predict(extended_dev_count_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bdd1250a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN with count feature Score\n",
      "Accuracy:  0.64\n",
      "Precision:  0.66\n",
      "Recall:  0.64\n",
      "F1 Socre:  0.65\n"
     ]
    }
   ],
   "source": [
    "knn_count_score = evaluate(knn_count_predict, dev_label)\n",
    "print(\"KNN with count feature Score\")\n",
    "print(\"Accuracy: \", round(knn_count_score[0],2))\n",
    "print(\"Precision: \", round(knn_count_score[1],2))\n",
    "print(\"Recall: \", round(knn_count_score[2],2))\n",
    "print(\"F1 Socre: \", round(knn_count_score[3],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3544035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_tfidf = KNeighborsClassifier(n_neighbors=23)\n",
    "knn_tfidf.fit(extended_train_tfidf_fea, train_label)\n",
    "knn_tfidf_predict = knn_tfidf.predict(extended_dev_count_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "716f6730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN with tfidf feature Score\n",
      "Accuracy:  0.66\n",
      "Precision:  0.69\n",
      "Recall:  0.66\n",
      "F1 Socre:  0.67\n"
     ]
    }
   ],
   "source": [
    "knn_tfidf_score = evaluate(knn_tfidf_predict, dev_label)\n",
    "print(\"KNN with tfidf feature Score\")\n",
    "print(\"Accuracy: \", round(knn_tfidf_score[0],2))\n",
    "print(\"Precision: \", round(knn_tfidf_score[1],2))\n",
    "print(\"Recall: \", round(knn_tfidf_score[2],2))\n",
    "print(\"F1 Socre: \", round(knn_tfidf_score[3],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd1ab635",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_glove = KNeighborsClassifier(n_neighbors=23)\n",
    "knn_glove.fit(train_glove_fea, train_label)\n",
    "knn_glove_predict = knn_glove.predict(dev_glove_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dc594add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN with glove feature Score\n",
      "Accuracy:  0.63\n",
      "Precision:  0.7\n",
      "Recall:  0.63\n",
      "F1 Socre:  0.65\n"
     ]
    }
   ],
   "source": [
    "knn_glove_score = evaluate(knn_glove_predict, dev_label)\n",
    "print(\"KNN with glove feature Score\")\n",
    "print(\"Accuracy: \", round(knn_glove_score[0],2))\n",
    "print(\"Precision: \", round(knn_glove_score[1],2))\n",
    "print(\"Recall: \", round(knn_glove_score[2],2))\n",
    "print(\"F1 Socre: \", round(knn_glove_score[3],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59131e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test the influce of parameter k to knn algorithm\n",
    "def knn_predict(test_fea, train_fea, train_label, k):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(train_fea, train_label)\n",
    "    predict = knn.predict(test_fea)\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eae64937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is:  0.6315683713453231\n",
      "best k is:  23\n"
     ]
    }
   ],
   "source": [
    "best_score = 0.0\n",
    "best_k = 0\n",
    "for k in range(1, 25):\n",
    "    y_predict = knn_predict(dev_glove_fea, train_glove_fea, train_label, k)\n",
    "    score = sum(y_predict == dev_label) / len(dev_label)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_k = k\n",
    "print(\"best score is: \", best_score)\n",
    "print(\"best k is: \", best_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add20105",
   "metadata": {},
   "source": [
    "#### Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1756006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8a8649e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_count = DecisionTreeClassifier(max_depth=9)\n",
    "dt_count.fit(extended_train_count_fea, train_label)\n",
    "dt_count_predict = dt_count.predict(extended_dev_count_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "45a04729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree with count feature Score\n",
      "Accuracy:  0.46\n",
      "Precision:  0.57\n",
      "Recall:  0.4\n",
      "F1 Socre:  0.35\n"
     ]
    }
   ],
   "source": [
    "dt_count_score = evaluate(dt_count_predict, dev_label)\n",
    "print(\"Decision Tree with count feature Score\")\n",
    "print(\"Accuracy: \", round(dt_count_score[0],2))\n",
    "print(\"Precision: \", round(dt_count_score[1],2))\n",
    "print(\"Recall: \", round(dt_count_score[2],2))\n",
    "print(\"F1 Socre: \", round(dt_count_score[3],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ad1351e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_tfidf = DecisionTreeClassifier(max_depth=9)\n",
    "dt_tfidf.fit(extended_train_tfidf_fea, train_label)\n",
    "dt_tfidf_predict = dt_tfidf.predict(extended_dev_count_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c258be51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree with tfidf feature Score\n",
      "Accuracy:  0.46\n",
      "Precision:  0.57\n",
      "Recall:  0.4\n",
      "F1 Socre:  0.35\n"
     ]
    }
   ],
   "source": [
    "dt_tfidf_score = evaluate(dt_tfidf_predict, dev_label)\n",
    "print(\"Decision Tree with tfidf feature Score\")\n",
    "print(\"Accuracy: \", round(dt_tfidf_score[0],2))\n",
    "print(\"Precision: \", round(dt_tfidf_score[1],2))\n",
    "print(\"Recall: \", round(dt_tfidf_score[2],2))\n",
    "print(\"F1 Socre: \", round(dt_tfidf_score[3],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "94898f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_glove = DecisionTreeClassifier(max_depth=9)\n",
    "dt_glove.fit(train_glove_fea, train_label)\n",
    "dt_glove_predict = dt_glove.predict(dev_glove_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2fb65cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree with glove feature Score\n",
      "Accuracy:  0.59\n",
      "Precision:  0.62\n",
      "Recall:  0.6\n",
      "F1 Socre:  0.61\n"
     ]
    }
   ],
   "source": [
    "dt_glove_score = evaluate(dt_glove_predict, dev_label)\n",
    "print(\"Decision Tree with glove feature Score\")\n",
    "print(\"Accuracy: \", round(dt_glove_score[0],2))\n",
    "print(\"Precision: \", round(dt_glove_score[1],2))\n",
    "print(\"Recall: \", round(dt_glove_score[2],2))\n",
    "print(\"F1 Socre: \", round(dt_glove_score[3],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d22c7147",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test the influce of parameter max_depth to dt algorithm\n",
    "def dt(test_fea, train_fea, train_label, k):\n",
    "    dt = DecisionTreeClassifier(max_depth=k)\n",
    "    dt.fit(extended_train_count_fea, train_label)\n",
    "    predict = dt.predict(extended_dev_count_fea)\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72c8e408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is:  0.4629759871395559\n",
      "best k is:  9\n"
     ]
    }
   ],
   "source": [
    "best_score = 0.0\n",
    "best_k = 0\n",
    "for k in range(1, 10):\n",
    "    y_predict = dt(dev_glove_fea, train_glove_fea, train_label, k)\n",
    "    score = sum(y_predict == dev_label) / len(dev_label)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_k = k\n",
    "print(\"best score is: \", best_score)\n",
    "print(\"best k is: \", best_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171e0237",
   "metadata": {},
   "source": [
    "#### Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab2a88fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5457758",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_count = MLPClassifier(solver='adam', activation='tanh', hidden_layer_sizes=(2,2))\n",
    "mlp_count.fit(extended_train_count_fea, train_label)\n",
    "mlp_count_predict = mlp_count.predict(extended_dev_count_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "562873fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-layer Perceptron with count feature Score\n",
      "Accuracy:  0.74\n",
      "Precision:  0.75\n",
      "Recall:  0.75\n",
      "F1 Socre:  0.75\n"
     ]
    }
   ],
   "source": [
    "mlp_count_score = evaluate(mlp_count_predict, dev_label)\n",
    "print(\"Multi-layer Perceptron with count feature Score\")\n",
    "print(\"Accuracy: \", round(mlp_count_score[0],2))\n",
    "print(\"Precision: \", round(mlp_count_score[1],2))\n",
    "print(\"Recall: \", round(mlp_count_score[2],2))\n",
    "print(\"F1 Socre: \", round(mlp_count_score[3],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47c5ee2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_tfidf = MLPClassifier(solver='adam', activation='tanh', hidden_layer_sizes=(2,2))\n",
    "mlp_tfidf.fit(extended_train_tfidf_fea, train_label)\n",
    "mlp_tfidf_predict = mlp_tfidf.predict(extended_dev_count_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "265299d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-layer Perceptron with tfidf feature Score\n",
      "Accuracy:  0.72\n",
      "Precision:  0.75\n",
      "Recall:  0.73\n",
      "F1 Socre:  0.74\n"
     ]
    }
   ],
   "source": [
    "mlp_tfidf_score = evaluate(mlp_tfidf_predict, dev_label)\n",
    "print(\"Multi-layer Perceptron with tfidf feature Score\")\n",
    "print(\"Accuracy: \", round(mlp_tfidf_score[0],2))\n",
    "print(\"Precision: \", round(mlp_tfidf_score[1],2))\n",
    "print(\"Recall: \", round(mlp_tfidf_score[2],2))\n",
    "print(\"F1 Socre: \", round(mlp_tfidf_score[3],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd46dc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_glove = MLPClassifier(solver='adam', activation='tanh', hidden_layer_sizes=(2,2))\n",
    "mlp_glove.fit(train_glove_fea, train_label)\n",
    "mlp_glove_predict = mlp_glove.predict(dev_glove_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd3f9b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-layer Perceptron with glove feature Score\n",
      "Accuracy:  0.68\n",
      "Precision:  0.7\n",
      "Recall:  0.7\n",
      "F1 Socre:  0.7\n"
     ]
    }
   ],
   "source": [
    "mlp_glove_score = evaluate(mlp_glove_predict, dev_label)\n",
    "print(\"Multi-layer Perceptron with glove feature Score\")\n",
    "print(\"Accuracy: \", round(mlp_glove_score[0],2))\n",
    "print(\"Precision: \", round(mlp_glove_score[1],2))\n",
    "print(\"Recall: \", round(mlp_glove_score[2],2))\n",
    "print(\"F1 Socre: \", round(mlp_glove_score[3],2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27da9fb",
   "metadata": {},
   "source": [
    "#### Predict the text value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7c3e21e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr_test = LogisticRegression().fit(extended_train_tfidf_fea, train_label)\n",
    "lr_test_predict = lr_test.predict(extended_test_tfidf_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b794c297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(columns=['tweet_id', 'sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a084e582",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = open(\"./data/test_full.csv\",'r').readlines()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "78fcdfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_id = []\n",
    "for line in tweet:\n",
    "    tweet_id.append(eval(line.strip().split(\",\")[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1dd159aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tweet_id\"] = tweet_id\n",
    "df[\"sentiment\"] = lr_test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "222e4769",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('result.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
